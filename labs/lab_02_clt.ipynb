{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem (CLT)\n",
    "\n",
    "**CLT Statement:**\n",
    "* The CLT states that the distribution of the sample mean ($\\bar{X}$) of $N$ i.i.d. random variables approaches a normal distribution as $N$ increases, regardless of the original distribution (provided it has a finite mean and variance).\n",
    "* Specifically:\n",
    "    * $\\bar{X} \\approx N(\\mu, \\frac{\\sigma^2}{N})$\n",
    "    * Where $\\mu$ is the population mean and $\\sigma^2$ is the population variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment to empirically observe the CLT in action\n",
    "\n",
    "Run a bunch of experiments (n_experiments), in which you should:\n",
    "1. Draw N samples from a non-Gaussian distribution: \n",
    "(e.g., a uniform distribution, an exponential distribution, etc.)\n",
    "\n",
    "2. Compute the empirical mean of the samples\n",
    "\n",
    "3. Plot the histogram of the empirical means\n",
    "\n",
    "4. Plot the pdf of a Gaussian distribution, with the mean and variance of the true distribution you were drawing the data from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up the true distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the true distribution\n",
    "# Uniform distribution\n",
    "\n",
    "# Exponential distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of experiments\n",
    "n_experiments = 10000\n",
    "\n",
    "# Initialize the array of empirical means\n",
    "sample_means = np.zeros(n_experiments)\n",
    "# Initialize the array of empirical variances\n",
    "sample_vars = np.zeros(n_experiments)\n",
    "\n",
    "# Define the number of samples\n",
    "N = 1000\n",
    "\n",
    "# Define the number of bins for the histogram\n",
    "n_bins = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the empirical means\n",
    "\n",
    "# Plot the Gaussian distribution defined by the Central Limit Theorem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation and the Central Limit Theorem (CLT)\n",
    "\n",
    "A use-case with the Bernoulli Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Distribution and MLE\n",
    "\n",
    "1.  **Bernoulli Distribution:**\n",
    "    * As before, we have a Bernoulli($p$) distribution, where $p$ is the probability of success (e.g., heads).\n",
    "    * We have $N$ independent and identically distributed (i.i.d.) samples: $X_1, X_2, ..., X_N$.\n",
    "\n",
    "2.  **Likelihood Function:**\n",
    "    * The likelihood function $L(p)$ represents the probability of observing our samples given a value of $p$.\n",
    "    * For Bernoulli, the likelihood is:\n",
    "        * $L(p) = p^{\\sum X_i} (1 - p)^{N - \\sum X_i}$\n",
    "\n",
    "3.  **MLE of $p$:**\n",
    "    * To find the MLE of $p$, we maximize the likelihood function (or its logarithm).\n",
    "    * Taking the derivative of the log-likelihood and setting it to zero, we find:\n",
    "        * $\\hat{p}_{MLE} = \\frac{1}{N} \\sum X_i = \\bar{X}$\n",
    "    * This shows that the MLE of $p$ is simply the sample mean ($\\bar{X}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Limit Theorem (CLT): Application to Bernoulli estimation\n",
    "* For Bernoulli($p$):\n",
    "    * $\\mu = p$\n",
    "    * $\\sigma^2 = p(1 - p)$\n",
    "* Therefore, according to the CLT:\n",
    "    * $\\bar{X} \\approx N(p, \\frac{p(1 - p)}{N})$\n",
    "\n",
    "* The CLT tells us that the distribution of $\\bar{X}$ (and therefore the MLE of $p$) approaches a normal distribution as $N$ increases.\n",
    "    * This means that the MLE ($\\hat{p}_{MLE}$) is approximately normally distributed around the true value $p$, with a variance of $\\frac{p(1 - p)}{N}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli MLE and CLT: Empirical validation\n",
    "\n",
    "1.  **Simulation:**\n",
    "    * Generate many sets of $N$ Bernoulli samples with a known $p$.\n",
    "    * For each set, calculate the sample mean ($\\bar{X}$), which is the MLE of $p$.\n",
    "    * Plot a histogram of the calculated sample means.\n",
    "\n",
    "2.  **Observations:**\n",
    "    * As $N$ increases, the histogram will increasingly resemble a normal distribution centered around $p$.\n",
    "    * The variance of the sample means will decrease as $N$ increases, illustrating the $\\frac{1}{N}$ term in the CLT.\n",
    "    * This demonstrates that the MLE (sample mean) is asymptotically normally distributed, a direct consequence of the CLT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment to show Bernoulli distribution's MLE follows a normal distribution, as per the Central Limit Theorem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of experiments\n",
    "n_experiments = 10000\n",
    "\n",
    "# Define the true distribution\n",
    "true_dist = None\n",
    "\n",
    "# Define the number of samples\n",
    "N = 1000\n",
    "\n",
    "# Define the number of bins for the histogram\n",
    "n_bins = 50\n",
    "\n",
    "# Set-up experiments\n",
    "# Initialize the array of empirical means\n",
    "sample_means = np.zeros(n_experiments)\n",
    "\n",
    "# Loop over the experiments\n",
    "\n",
    "# Plot the histogram of the empirical means\n",
    "\n",
    "# Plot the Gaussian distribution defined by the Central Limit Theorem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "* This connection is fundamental in statistical inference, as it allows us to construct confidence intervals and perform hypothesis tests based on the MLE.\n",
    "* This example can be generalized to other distributions where the sample mean is the MLE of the mean parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025_stats_for_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
